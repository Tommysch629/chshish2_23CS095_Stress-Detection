{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "test_dir= 'data/test/'\n",
    "\n",
    "num_train = 28709\n",
    "num_val = 3589\n",
    "num_test = 3589\n",
    "batch_size = 128\n",
    "num_epoch = 20\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(train_dir,\n",
    "                                    target_size=(48, 48),\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    color_mode=\"grayscale\",\n",
    "                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48, 48),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(48, 48),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Checkpoint_Callback = ModelCheckpoint('best_model.h5', \n",
    "                                            monitor='val_accuracy', \n",
    "                                            verbose=1, \n",
    "                                            save_best_only=True, \n",
    "                                            mode='max',\n",
    "                                            save_freq = \"epoch\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              factor=0.75,\n",
    "                              patience=5,\n",
    "                              verbose=1,\n",
    "                              mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommy\\AppData\\Local\\Temp\\ipykernel_15776\\3403903270.py:47: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(generator=train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - ETA: 0s - loss: 1.9589 - accuracy: 0.2649\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17439, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommy\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 747s 3s/step - loss: 1.9589 - accuracy: 0.2649 - val_loss: 1.8744 - val_accuracy: 0.1744 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 1.5921 - accuracy: 0.3657\n",
      "Epoch 2: val_accuracy improved from 0.17439 to 0.29464, saving model to best_model.h5\n",
      "224/224 [==============================] - 732s 3s/step - loss: 1.5921 - accuracy: 0.3657 - val_loss: 1.7604 - val_accuracy: 0.2946 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 1.3499 - accuracy: 0.4784\n",
      "Epoch 3: val_accuracy improved from 0.29464 to 0.47656, saving model to best_model.h5\n",
      "224/224 [==============================] - 778s 3s/step - loss: 1.3499 - accuracy: 0.4784 - val_loss: 1.3323 - val_accuracy: 0.4766 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 1.1878 - accuracy: 0.5454\n",
      "Epoch 4: val_accuracy improved from 0.47656 to 0.50167, saving model to best_model.h5\n",
      "224/224 [==============================] - 786s 4s/step - loss: 1.1878 - accuracy: 0.5454 - val_loss: 1.2745 - val_accuracy: 0.5017 - lr: 0.0100\n",
      "Epoch 5/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 1.0676 - accuracy: 0.5929\n",
      "Epoch 5: val_accuracy improved from 0.50167 to 0.55971, saving model to best_model.h5\n",
      "224/224 [==============================] - 738s 3s/step - loss: 1.0676 - accuracy: 0.5929 - val_loss: 1.1797 - val_accuracy: 0.5597 - lr: 0.0100\n",
      "Epoch 6/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.9686 - accuracy: 0.6352\n",
      "Epoch 6: val_accuracy improved from 0.55971 to 0.57227, saving model to best_model.h5\n",
      "224/224 [==============================] - 748s 3s/step - loss: 0.9686 - accuracy: 0.6352 - val_loss: 1.1155 - val_accuracy: 0.5723 - lr: 0.0100\n",
      "Epoch 7/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.6752\n",
      "Epoch 7: val_accuracy did not improve from 0.57227\n",
      "224/224 [==============================] - 730s 3s/step - loss: 0.8645 - accuracy: 0.6752 - val_loss: 1.1987 - val_accuracy: 0.5686 - lr: 0.0100\n",
      "Epoch 8/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.7598 - accuracy: 0.7167\n",
      "Epoch 8: val_accuracy improved from 0.57227 to 0.57701, saving model to best_model.h5\n",
      "224/224 [==============================] - 731s 3s/step - loss: 0.7598 - accuracy: 0.7167 - val_loss: 1.1510 - val_accuracy: 0.5770 - lr: 0.0100\n",
      "Epoch 9/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.7581\n",
      "Epoch 9: val_accuracy did not improve from 0.57701\n",
      "224/224 [==============================] - 731s 3s/step - loss: 0.6497 - accuracy: 0.7581 - val_loss: 1.2711 - val_accuracy: 0.5720 - lr: 0.0100\n",
      "Epoch 10/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.7980\n",
      "Epoch 10: val_accuracy improved from 0.57701 to 0.59738, saving model to best_model.h5\n",
      "224/224 [==============================] - 744s 3s/step - loss: 0.5452 - accuracy: 0.7980 - val_loss: 1.2952 - val_accuracy: 0.5974 - lr: 0.0100\n",
      "Epoch 11/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.8364\n",
      "Epoch 11: val_accuracy did not improve from 0.59738\n",
      "224/224 [==============================] - 776s 3s/step - loss: 0.4469 - accuracy: 0.8364 - val_loss: 1.6994 - val_accuracy: 0.5474 - lr: 0.0100\n",
      "Epoch 12/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8729\n",
      "Epoch 12: val_accuracy did not improve from 0.59738\n",
      "224/224 [==============================] - 770s 3s/step - loss: 0.3597 - accuracy: 0.8729 - val_loss: 1.7120 - val_accuracy: 0.5739 - lr: 0.0100\n",
      "Epoch 13/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.9024\n",
      "Epoch 13: val_accuracy did not improve from 0.59738\n",
      "224/224 [==============================] - 733s 3s/step - loss: 0.2822 - accuracy: 0.9024 - val_loss: 1.5868 - val_accuracy: 0.5918 - lr: 0.0100\n",
      "Epoch 14/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.9148\n",
      "Epoch 14: val_accuracy did not improve from 0.59738\n",
      "224/224 [==============================] - 735s 3s/step - loss: 0.2441 - accuracy: 0.9148 - val_loss: 1.8420 - val_accuracy: 0.5625 - lr: 0.0100\n",
      "Epoch 15/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.9352\n",
      "Epoch 15: val_accuracy improved from 0.59738 to 0.61049, saving model to best_model.h5\n",
      "224/224 [==============================] - 729s 3s/step - loss: 0.1900 - accuracy: 0.9352 - val_loss: 1.6900 - val_accuracy: 0.6105 - lr: 0.0100\n",
      "Epoch 16/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9505\n",
      "Epoch 16: val_accuracy did not improve from 0.61049\n",
      "224/224 [==============================] - 726s 3s/step - loss: 0.1482 - accuracy: 0.9505 - val_loss: 1.9243 - val_accuracy: 0.5971 - lr: 0.0100\n",
      "Epoch 17/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9551\n",
      "Epoch 17: val_accuracy did not improve from 0.61049\n",
      "224/224 [==============================] - 727s 3s/step - loss: 0.1312 - accuracy: 0.9551 - val_loss: 1.5929 - val_accuracy: 0.5954 - lr: 0.0100\n",
      "Epoch 18/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9684\n",
      "Epoch 18: val_accuracy did not improve from 0.61049\n",
      "224/224 [==============================] - 847s 4s/step - loss: 0.1004 - accuracy: 0.9684 - val_loss: 2.4112 - val_accuracy: 0.5773 - lr: 0.0100\n",
      "Epoch 19/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9728\n",
      "Epoch 19: val_accuracy did not improve from 0.61049\n",
      "224/224 [==============================] - 814s 4s/step - loss: 0.0879 - accuracy: 0.9728 - val_loss: 1.8928 - val_accuracy: 0.6021 - lr: 0.0100\n",
      "Epoch 20/20\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9788\n",
      "Epoch 20: val_accuracy did not improve from 0.61049\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "224/224 [==============================] - 731s 3s/step - loss: 0.0686 - accuracy: 0.9788 - val_loss: 2.2035 - val_accuracy: 0.6102 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, weight_decay=0.0001, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=num_train//batch_size,\n",
    "                              epochs=num_epoch,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=num_val//batch_size,\n",
    "                              callbacks=[Model_Checkpoint_Callback,reduce_lr]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_test = load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommy\\AppData\\Local\\Temp\\ipykernel_15776\\4109819777.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred = model_test.predict_generator(test_generator, num_test // batch_size+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[262   0  21  34  38 108   4]\n",
      " [ 12  22   2   4   3  13   0]\n",
      " [ 55   1 171  27  51 173  18]\n",
      " [ 31   0  11 721  60  66   6]\n",
      " [ 61   0  22  56 295 170   3]\n",
      " [ 83   0  29  38  76 423   4]\n",
      " [ 26   1  36  34  18  16 284]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = model_test.predict_generator(test_generator, num_test // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.49      0.56      0.53       467\n",
      "     disgust       0.92      0.39      0.55        56\n",
      "        fear       0.59      0.34      0.43       496\n",
      "       happy       0.79      0.81      0.80       895\n",
      "     neutral       0.55      0.49      0.51       607\n",
      "         sad       0.44      0.65      0.52       653\n",
      "    surprise       0.89      0.68      0.77       415\n",
      "\n",
      "    accuracy                           0.61      3589\n",
      "   macro avg       0.67      0.56      0.59      3589\n",
      "weighted avg       0.63      0.61      0.61      3589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "target_names = list(train_generator.class_indices.keys())\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
